{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5056857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from imutils.video import VideoStream\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93595f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file_path =\"face_detector/deploy.prototxt\"\n",
    "caffemodel_weights_Path = \"face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "Pretrain_face_detection_Model = cv2.dnn.readNet(txt_file_path, caffemodel_weights_Path)\n",
    "cls_model = load_model(\"MobileNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9effad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn=frame.copy()\n",
    "    frameHeight=frameOpencvDnn.shape[0]\n",
    "    frameWidth=frameOpencvDnn.shape[1]\n",
    "    blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections=net.forward()\n",
    "    faceBoxes=[]\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence=detections[0,0,i,2]\n",
    "        if confidence>conf_threshold:\n",
    "            x1=int(detections[0,0,i,3]*frameWidth)\n",
    "            y1=int(detections[0,0,i,4]*frameHeight)\n",
    "            x2=int(detections[0,0,i,5]*frameWidth)\n",
    "            y2=int(detections[0,0,i,6]*frameHeight)\n",
    "            faceBoxes.append([x1,y1,x2,y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn,faceBoxes\n",
    "\n",
    "faceProto=\"gad/opencv_face_detector.pbtxt\"\n",
    "faceModel=\"gad/opencv_face_detector_uint8.pb\"\n",
    "ageProto=\"gad/age_deploy.prototxt\"\n",
    "ageModel=\"gad/age_net.caffemodel\"\n",
    "genderProto=\"gad/gender_deploy.prototxt\"\n",
    "genderModel=\"gad/gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList=['Male','Female']\n",
    "\n",
    "faceNet=cv2.dnn.readNet(faceModel,faceProto)\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5664ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func(vid_path=''):\n",
    "        def Realtime_Detection_func(Video_frame, Pretrain_face_detection_Model,cls_model):\n",
    "\n",
    "            (height, width) = Video_frame.shape[:-1]\n",
    "            Img_blob = cv2.dnn.blobFromImage(Video_frame, 1.0, (224, 224),(104.0, 177.0, 123.0))\n",
    "\n",
    "            # pass the blob through the network and obtain the face detections\n",
    "            Pretrain_face_detection_Model.setInput(Img_blob)\n",
    "            face_identify = Pretrain_face_detection_Model.forward()\n",
    "            print(face_identify.shape)\n",
    "\n",
    "            # initialize our list of faces, their corresponding locations,\n",
    "            # and the list of predictions from our face mask network\n",
    "            faces_in_frame_lst = []\n",
    "            faces_location_lst = []\n",
    "            model_preds_lst = []\n",
    "\n",
    "            for i in range(0, face_identify.shape[2]):\n",
    "\n",
    "                conf_value = face_identify[0, 0, i, 2]\n",
    "                if conf_value > 0.6:\n",
    "\n",
    "                    Rectangle_box = face_identify[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "                    (starting_PointX, starting_PointY, ending_PointX, ending_PointY) = Rectangle_box.astype(\"int\")\n",
    "                    (starting_PointX, starting_PointY) = (max(0, starting_PointX), max(0, starting_PointY))\n",
    "                    (ending_PointX, ending_PointY) = (min(width - 1, ending_PointX), min(height - 1, ending_PointY))\n",
    "                    face_detect = vid_frm[starting_PointY:ending_PointY, starting_PointX:ending_PointX]\n",
    "                    face_RGB = cv2.cvtColor(face_detect, cv2.COLOR_BGR2RGB)\n",
    "                    face_Resize = cv2.resize(face_RGB, (224, 224))\n",
    "                    face_to_array = img_to_array(face_Resize)\n",
    "                    face_rescale = preprocess_input(face_to_array)\n",
    "\n",
    "                    faces_in_frame_lst.append(face_rescale)\n",
    "                    faces_location_lst.append((starting_PointX, starting_PointY, ending_PointX, ending_PointY))\n",
    "                    \n",
    "            if len(faces_in_frame_lst) > 0:\n",
    "\n",
    "                faces_in_frame_lst = np.array(faces_in_frame_lst, dtype=\"float32\")\n",
    "                model_preds_lst = cls_model.predict(faces_in_frame_lst, batch_size=16)\n",
    "\n",
    "            return (model_preds_lst, faces_location_lst)\n",
    "        if vid_path != '':\n",
    "            print(\"[INFO] starting video stream...\")\n",
    "            vid_stm = VideoStream(src=vid_path).start()\n",
    "        elif vid_path == '':\n",
    "            print(\"[INFO] starting live stream...\")\n",
    "            vid_stm = VideoStream(src=0).start()\n",
    "        while True:\n",
    "\n",
    "            vid_frm = vid_stm.read()\n",
    "            vid_frm = imutils.resize(vid_frm, width=800)\n",
    "            padding=20\n",
    "   \n",
    "            resultImg,faceBoxes=highlightFace(faceNet,vid_frm)\n",
    "            if not faceBoxes:\n",
    "                print(\"No face detected\")\n",
    "\n",
    "            (model_preds_lst, faces_location_lst) = Realtime_Detection_func(vid_frm, Pretrain_face_detection_Model, cls_model)\n",
    "\n",
    "            for (pred,Rectangle_box,faceBox) in zip(model_preds_lst, faces_location_lst,faceBoxes):\n",
    "                (starting_PointX, starting_PointY, ending_PointX, ending_PointY) = Rectangle_box\n",
    "                (mask_img, NoMask_img) = pred\n",
    "                \n",
    "                face=vid_frm[max(0,faceBox[1]-padding):\n",
    "                           min(faceBox[3]+padding,vid_frm.shape[0]-1),max(0,faceBox[0]-padding)\n",
    "                           :min(faceBox[2]+padding, vid_frm.shape[1]-1)]\n",
    "                blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                genderNet.setInput(blob)\n",
    "                genderPreds=genderNet.forward()\n",
    "                gender=genderList[genderPreds[0].argmax()]\n",
    "                print(f'Gender: {gender}')\n",
    "\n",
    "                ageNet.setInput(blob)\n",
    "                agePreds=ageNet.forward()\n",
    "                age=ageList[agePreds[0].argmax()]\n",
    "                print(f'Age: {age[1:-1]} years')\n",
    "\n",
    "                label = \"Mask\" if mask_img > NoMask_img else \"No Mask\"\n",
    "                color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "                #label = \"{}: {:.2f}%\".format(label, max(mask_img, NoMask_img) * 100)\n",
    "\n",
    "                cv2.putText(vid_frm, label+':'+f'   {gender}, {age}', (starting_PointX, starting_PointY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "                cv2.rectangle(vid_frm, (starting_PointX, starting_PointY), (ending_PointX, ending_PointY), color, 2)\n",
    "\n",
    "            cv2.imshow(\"Video Frame\", vid_frm)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        # do a bit of cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        vid_stm.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0948d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit():\n",
    "    #window.destroy()\n",
    "    window.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409eae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_15228/1895779018.py:21: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_image = original_image.resize((1500, 800), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, Button, Label, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "def main_menu():\n",
    "    def browseFiles():\n",
    "        filename = filedialog.askopenfilename(initialdir=\"/\",\n",
    "                                              title=\"Select a File\",\n",
    "                                              filetypes=((\"Text files\", \"*.mp4\"),\n",
    "                                                         (\"all files\", \"*.mp4\")))\n",
    "        label_file_explorer.configure(text=\"File Opened: \" + filename)\n",
    "        return filename\n",
    "\n",
    "    window = Tk()\n",
    "    window.title('Face Mask Detection')\n",
    "\n",
    "    # Set the window size\n",
    "    window.geometry(\"1500x800\")\n",
    "\n",
    "    # Adding a background image\n",
    "    original_image = Image.open(\"UI.png\")\n",
    "    resized_image = original_image.resize((1500, 800), Image.ANTIALIAS)\n",
    "    bg_image = ImageTk.PhotoImage(resized_image)\n",
    "\n",
    "    background_label = Label(window, image=bg_image)\n",
    "    background_label.place(relwidth=1, relheight=1)\n",
    "    background_label.image = bg_image\n",
    "\n",
    "    button_explore = Button(window,\n",
    "                            text=\"Browse Files\",\n",
    "                            command=browseFiles,\n",
    "                            font=(\"Helvetica\", 20),\n",
    "                            bg=\"green\", fg=\"white\")\n",
    "\n",
    "    button_live_stream = Button(window,\n",
    "                                text=\"Live Stream\",\n",
    "                                command=main_func,\n",
    "                                font=(\"Helvetica\", 20),\n",
    "                                bg=\"orange\", fg=\"white\")\n",
    "\n",
    "    button_video_stream = Button(window,\n",
    "                                 text=\"Video Stream\",\n",
    "                                 command=lambda: main_func(browseFiles()),\n",
    "                                 font=(\"Helvetica\", 20),\n",
    "                                 bg=\"red\", fg=\"white\")\n",
    "\n",
    "    button_exit = Button(window,\n",
    "                         text=\"Exit\",\n",
    "                         command=exit,\n",
    "                         font=(\"Helvetica\", 20),\n",
    "                         bg=\"gray\", fg=\"white\")\n",
    "\n",
    "    # Place the buttons using coordinates (x, y)\n",
    "    button_explore.place(x=700, y=325)\n",
    "    button_live_stream.place(x=700, y=400)\n",
    "    button_video_stream.place(x=700, y=475)\n",
    "    button_exit.place(x=700, y= 550)\n",
    "\n",
    "    window.mainloop()\n",
    "\n",
    "# Add your main_func definition here\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_menu()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
